{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjMZbEdtoh_",
        "outputId": "259012d8-f6ac-456e-fcad-b5bcb9ef30de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-07 22:15:02--  https://raw.githubusercontent.com/eonurk/eksiGPT/c03b0394808b724a89f519ba9457f0bc623bbc23/data/eksi_articles.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3647853 (3.5M) [text/plain]\n",
            "Saving to: ‘eksi_articles.txt’\n",
            "\n",
            "eksi_articles.txt   100%[===================>]   3.48M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-12-07 22:15:03 (44.1 MB/s) - ‘eksi_articles.txt’ saved [3647853/3647853]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# başlamak için verisetini indiriyoruz.\n",
        "\n",
        "!wget https://raw.githubusercontent.com/eonurk/eksiGPT/c03b0394808b724a89f519ba9457f0bc623bbc23/data/eksi_articles.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hadi veriyi inceleyelim.\n",
        "with open('eksi_articles.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "yhi7b10wuCAw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ilk 2000 karaktere bakalım\n",
        "print(text[:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G9ZpYGwuU1t",
        "outputId": "db7e23b5-763f-416a-ca05-a088bb633c0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: TARİH\n",
            "Category: TARİH\n",
            "\n",
            "Content:\n",
            "1741 yılında yedi aylık bir deniz yolculuğunun ardından hollandalı kaptan douwemout van der meer, dişi genç bir hint gergedanıyla rotterdam limanına geldi. 1579 yılından bu yana avrupa'ya gelen ilk gergedandı bu!\n",
            "\n",
            "avrupalılar için gergedan, tek boynuzlu at kadar efsanevi bir varlıktı. o güne dek gerçekten yaşadığına bir çok insanın inanmadığı hayvanın gerçekten var olduğunun tek kanıtı albrecht dürer'in 1515 tarihli gravür baskısıydı.\n",
            "\n",
            "bayan clara ismi konulan dişi hint gergedanı, 1744'te almanya'nın hamburg kentine ilk gezisini yapmadan önce birkaç yıl boyunca hollanda'da sergilendi . ardından tüm avrupayı gezen gergedan 3 kez de ingiltere'ye götürüldü ( bu seyahatler sırasında onu taşıyamadığı için çöken vagonlar, roma'da olduğu sırada kapalı tutulduğu ağırda sıkılıp boynuzunu ahşap duvarlara sürterek kırması gibi pek çok detayla sizi sıkmayalım).\n",
            "\n",
            "hayatta olduğu süreçte avrupa'da bir gergedan çılgınlığı başladı. çok sayıda gergedan temalı hediyelik eşyalar, resimler vb üretildi ve satıldı. dönemin ünlü ressamları fransız ressam jean-baptiste oudry, venedikli ressam pietro longhi gibi.\n",
            "\n",
            "isimlerin tabloları ünlü müzelerde sergilendi. bronz ve mermerden heykelleri yapılıp ünlü mekanlara konulurken, çizimleri anatomi atlaslarına girdi.\n",
            "\n",
            "aslında clara'nın hikayesi çok acıklı başlamıştı, annesi 17387'te hindistan'da öldürülünce bir hollandalı yönetici'nin evinin bahçesinde \" evcil bir hayvan olarak \" kaldı bir kaç yıl. 1740'da onu kaptan van der meer satın aldı ve ona çok iyi bakarak ülkesine götürdü. avrupa'ya getirilmeye çalışılan ya da getirilen pek çok egzotik hayvan ya yolda ya da karaya ayak bastıktan kısa süre sonra ölmüştü. diğerlerinden çok daha uzun yaşasa da clara nisan 1758'te londra'da öldü ( nedeni bilinmiyor).\n",
            "\n",
            "## Gladyatör Filminde Maliyetli ve Zor Olacağı Düşünülerek Vazgeçilen Gergedan Sahnesi\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Title: İngiltere'de Cenazelere Profesy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"karakter sayısı: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rB8fCviurOF",
        "outputId": "53f14b98-f94f-4583-d03f-7c17677af938"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "karakter sayısı:  3359477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "karakter = sorted(set(text))\n",
        "sozluk_buyuklugu = len(karakter)\n",
        "print(\"karakter sayısı: \", sozluk_buyuklugu)\n",
        "print(\"\".join(karakter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBSuhfTuu53W",
        "outputId": "443b6a65-f7bf-48ab-aecc-73ee8b90cd15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "karakter sayısı:  135\n",
            "\n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz| £¯°´ÇÖ×ÜàáâäçèéêëíîñóôöúûüĞğİıŞşš–—‘’“”•…€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# karakterleri sayılara çevirelim\n",
        "ceviri = { ch:i for i,ch in enumerate(karakter) }\n",
        "irivec = { i:ch for i,ch in enumerate(karakter) }\n",
        "\n",
        "encode = lambda s: [ceviri[c] for c in s] # encoder: bi kelimeyi sayiya cevirir\n",
        "decode = lambda l: ''.join([irivec[i] for i in l]) # decode: sayiyi kelimeye cevirir\n",
        "\n",
        "\n",
        "girdi = \"onur bu video olmadi\"\n",
        "cikti = encode(girdi)\n",
        "\n",
        "print(cikti)\n",
        "print(decode(cikti))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY8rt5xjvc-b",
        "outputId": "23a879fd-5364-44e3-9014-3d63cb9ff339"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[79, 78, 85, 82, 1, 66, 85, 1, 86, 73, 68, 69, 79, 1, 79, 76, 77, 65, 68, 73]\n",
            "onur bu video olmadi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRD8ChDdxCrQ",
        "outputId": "5ba36cb6-787e-43e6-a009-f38d3d8ecc19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3359477]) torch.int64\n",
            "tensor([ 53,  73,  84,  76,  69,  27,   1,  53,  34,  51, 121,  41,   0,  36,\n",
            "         65,  84,  69,  71,  79,  82,  89,  27,   1,  53,  34,  51, 121,  41,\n",
            "          0,   0,  36,  79,  78,  84,  69,  78,  84,  27,   0,  18,  24,  21,\n",
            "         18,   1,  89, 122,  76, 122,  78,  68,  65,   1,  89,  69,  68,  73,\n",
            "          1,  65,  89,  76, 122,  75,   1,  66,  73,  82,   1,  68,  69,  78,\n",
            "         73,  90,   1,  89,  79,  76,  67,  85,  76,  85, 120,  85,  78,  85,\n",
            "         78,   1,  65,  82,  68, 122,  78,  68,  65,  78,   1,  72,  79,  76,\n",
            "         76,  65,  78,  68,  65,  76, 122,   1,  75,  65,  80,  84,  65,  78,\n",
            "          1,  68,  79,  85,  87,  69,  77,  79,  85,  84,   1,  86,  65,  78,\n",
            "          1,  68,  69,  82,   1,  77,  69,  69,  82,  13,   1,  68,  73, 124,\n",
            "         73,   1,  71,  69,  78, 105,   1,  66,  73,  82,   1,  72,  73,  78,\n",
            "         84,   1,  71,  69,  82,  71,  69,  68,  65,  78, 122,  89,  76,  65,\n",
            "          1,  82,  79,  84,  84,  69,  82,  68,  65,  77,   1,  76,  73,  77,\n",
            "         65,  78, 122,  78,  65,   1,  71,  69,  76,  68,  73,  15,   1,  18,\n",
            "         22,  24,  26,   1,  89, 122,  76, 122,  78,  68,  65,  78,   1,  66,\n",
            "         85,   1,  89,  65,  78,  65,   1,  65,  86,  82,  85,  80,  65,   8,\n",
            "         89,  65,   1,  71,  69,  76,  69,  78,   1,  73,  76,  75,   1,  71,\n",
            "         69,  82,  71,  69,  68,  65,  78,  68, 122,   1,  66,  85,   2,   0,\n",
            "          0,  65,  86,  82,  85,  80,  65,  76, 122,  76,  65,  82,   1,  73,\n",
            "        105,  73,  78,   1,  71,  69,  82,  71,  69,  68,  65,  78,  13,   1,\n",
            "         84,  69,  75,   1,  66,  79,  89,  78,  85,  90,  76,  85,   1,  65,\n",
            "         84,   1,  75,  65,  68,  65,  82,   1,  69,  70,  83,  65,  78,  69,\n",
            "         86,  73,   1,  66,  73,  82,   1,  86,  65,  82,  76, 122,  75,  84,\n",
            "        122,  15,   1,  79,   1,  71, 118,  78,  69,   1,  68,  69,  75,   1,\n",
            "         71,  69,  82, 105,  69,  75,  84,  69,  78,   1,  89,  65, 124,  65,\n",
            "         68, 122, 120, 122,  78,  65,   1,  66,  73,  82,   1, 105,  79,  75,\n",
            "          1,  73,  78,  83,  65,  78, 122,  78,   1,  73,  78,  65,  78,  77,\n",
            "         65,  68, 122, 120, 122,   1,  72,  65,  89,  86,  65,  78, 122,  78,\n",
            "          1,  71,  69,  82, 105,  69,  75,  84,  69,  78,   1,  86,  65,  82,\n",
            "          1,  79,  76,  68,  85, 120,  85,  78,  85,  78,   1,  84,  69,  75,\n",
            "          1,  75,  65,  78, 122,  84, 122,   1,  65,  76,  66,  82,  69,  67,\n",
            "         72,  84,   1,  68, 118,  82,  69,  82,   8,  73,  78,   1,  18,  22,\n",
            "         18,  22,   1,  84,  65,  82,  73,  72,  76,  73,   1,  71,  82,  65,\n",
            "         86, 118,  82,   1,  66,  65,  83,  75, 122,  83, 122,  89,  68, 122,\n",
            "         15,   0,   0,  66,  65,  89,  65,  78,   1,  67,  76,  65,  82,  65,\n",
            "          1,  73,  83,  77,  73,   1,  75,  79,  78,  85,  76,  65,  78,   1,\n",
            "         68,  73, 124,  73,   1,  72,  73,  78,  84,   1,  71,  69,  82,  71,\n",
            "         69,  68,  65,  78, 122,  13,   1,  18,  24,  21,  21,   8,  84,  69,\n",
            "          1,  65,  76,  77,  65,  78,  89,  65,   8,  78, 122,  78,   1,  72,\n",
            "         65,  77,  66,  85,  82,  71,   1,  75,  69,  78,  84,  73,  78,  69,\n",
            "          1,  73,  76,  75,   1,  71,  69,  90,  73,  83,  73,  78,  73,   1,\n",
            "         89,  65,  80,  77,  65,  68,  65,  78,   1, 115,  78,  67,  69,   1,\n",
            "         66,  73,  82,  75,  65, 105,   1,  89, 122,  76,   1,  66,  79,  89,\n",
            "         85,  78,  67,  65,   1,  72,  79,  76,  76,  65,  78,  68,  65,   8,\n",
            "         68,  65,   1,  83,  69,  82,  71,  73,  76,  69,  78,  68,  73,   1,\n",
            "         15,   1,  65,  82,  68, 122,  78,  68,  65,  78,   1,  84, 118,  77,\n",
            "          1,  65,  86,  82,  85,  80,  65,  89, 122,   1,  71,  69,  90,  69,\n",
            "         78,   1,  71,  69,  82,  71,  69,  68,  65,  78,   1,  20,   1,  75,\n",
            "         69,  90,   1,  68,  69,   1,  73,  78,  71,  73,  76,  84,  69,  82,\n",
            "         69,   8,  89,  69,   1,  71, 115,  84, 118,  82, 118,  76,  68, 118,\n",
            "          1,   9,   1,  66,  85,   1,  83,  69,  89,  65,  72,  65,  84,  76,\n",
            "         69,  82,   1,  83, 122,  82,  65,  83, 122,  78,  68,  65,   1,  79,\n",
            "         78,  85,   1,  84,  65, 124, 122,  89,  65,  77,  65,  68, 122, 120,\n",
            "        122,   1,  73, 105,  73,  78,   1, 105, 115,  75,  69,  78,   1,  86,\n",
            "         65,  71,  79,  78,  76,  65,  82,  13,   1,  82,  79,  77,  65,   8,\n",
            "         68,  65,   1,  79,  76,  68,  85, 120,  85,   1,  83, 122,  82,  65,\n",
            "         68,  65,   1,  75,  65,  80,  65,  76, 122,   1,  84,  85,  84,  85,\n",
            "         76,  68,  85, 120,  85,   1,  65, 120, 122,  82,  68,  65,   1,  83,\n",
            "        122,  75, 122,  76, 122,  80,   1,  66,  79,  89,  78,  85,  90,  85,\n",
            "         78,  85,   1,  65,  72, 124,  65,  80,   1,  68,  85,  86,  65,  82,\n",
            "         76,  65,  82,  65,   1,  83, 118,  82,  84,  69,  82,  69,  75,   1,\n",
            "         75, 122,  82,  77,  65,  83, 122,   1,  71,  73,  66,  73,   1,  80,\n",
            "         69,  75,   1, 105,  79,  75,   1,  68,  69,  84,  65,  89,  76,  65,\n",
            "          1,  83,  73,  90,  73,   1,  83, 122,  75,  77,  65,  89,  65,  76,\n",
            "        122,  77,  10,  15,   0,   0,  72,  65,  89,  65,  84,  84,  65,   1,\n",
            "         79,  76,  68,  85, 120,  85,   1,  83, 118,  82,  69, 105,  84,  69,\n",
            "          1,  65,  86,  82,  85,  80,  65,   8,  68,  65,   1,  66,  73,  82,\n",
            "          1,  71,  69,  82,  71,  69,  68,  65,  78,   1, 105, 122,  76,  71,\n",
            "        122,  78,  76, 122, 120, 122,   1,  66,  65, 124,  76,  65,  68, 122,\n",
            "         15,   1, 105,  79,  75,   1,  83,  65,  89, 122,  68,  65,   1,  71,\n",
            "         69,  82,  71,  69,  68,  65,  78,   1,  84,  69,  77,  65,  76, 122,\n",
            "          1,  72,  69,  68,  73,  89])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "print(n)\n",
        "\n",
        "egitim = data[:n]\n",
        "test = data[n:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBnUZjIDyu3_",
        "outputId": "05195301-6e02-454d-c890-39b60dd6e1c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3023529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pencere = 8\n",
        "\n",
        "decode(egitim[:pencere].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "sn0pZFgbzZ0H",
        "outputId": "2f47ebee-27d5-48a0-fbb1-a8847b349acc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Title: T'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next token prediction : sonraki heceyi tahmin\n",
        "\n",
        "x = egitim[:pencere]\n",
        "y = egitim[1:pencere+1]\n",
        "\n",
        "for t in range(pencere):\n",
        "    girdi = x[:t+1]\n",
        "    cikti = y[t]\n",
        "    print(f\"girdi: {girdi} cikti: {cikti}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrgDO9dz7CM",
        "outputId": "cfd99088-9de4-4b2e-aa0f-49f5ff0f6269"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "girdi: tensor([53]) cikti: 73\n",
            "girdi: tensor([53, 73]) cikti: 84\n",
            "girdi: tensor([53, 73, 84]) cikti: 76\n",
            "girdi: tensor([53, 73, 84, 76]) cikti: 69\n",
            "girdi: tensor([53, 73, 84, 76, 69]) cikti: 27\n",
            "girdi: tensor([53, 73, 84, 76, 69, 27]) cikti: 1\n",
            "girdi: tensor([53, 73, 84, 76, 69, 27,  1]) cikti: 53\n",
            "girdi: tensor([53, 73, 84, 76, 69, 27,  1, 53]) cikti: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "irivec[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "f2Yx9EJr3aAL",
        "outputId": "5cb84667-f544-4a13-bcd6-b8bdb45635c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(len(data) - pencere, (135,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkg7sMc2Eo92",
        "outputId": "f0195cf5-efee-499c-e14b-1f52136f8559"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1546264,  797554, 1705949,  485052, 2270829, 1203360, 2129173, 2947139,\n",
              "        1085689,  538805,  151156,  435356, 3258120, 2522716,  589448, 2542052,\n",
              "         115261,  242714, 1890832, 1328730, 2565749, 2295007, 2287857, 2303089,\n",
              "        3289217, 1754582, 2827161, 2343760,  334723, 2123318, 2352865, 1204149,\n",
              "        2069483,  276749,  456082,  592483, 2413798, 1574681, 2147049,  487989,\n",
              "         735639,  877637, 2493379, 2739212,  707954, 3089008,  417337, 1615266,\n",
              "         499017, 2254779, 2408388, 2262355, 1545691, 3217532, 3161126,  485672,\n",
              "        1194125, 2146393, 1494360,  737353,   62959, 1101906, 1444246, 3154669,\n",
              "        2499099, 2410634, 1213848, 1610670,   64055, 1842803, 3040945, 3281521,\n",
              "        2516767, 2092095, 1928027, 2294466,  802081,  278608, 3109042,   26537,\n",
              "        2646022, 2189404, 1673078, 1459536, 3150110, 1914237, 1163819, 1191150,\n",
              "        2298397, 1744189, 2052307, 1644274, 1187758,  509778, 2780471,  723546,\n",
              "         813747, 2880414, 1048853, 1218782, 3352672, 2960896, 3300502,  622818,\n",
              "        2219838,  219965,  488979, 2031986, 1571507, 1804378, 2959033, 1175413,\n",
              "        2314950,  228336, 2263715, 2648727, 2039237,  728257, 2560122, 1428026,\n",
              "        1980810,  557889, 1651011,  357580, 1007585, 1962497, 3020894, 1405480,\n",
              "        2895890,  826346,  608119, 1399190, 1502031,  844731,  124095])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kume = 4 # batch (B)\n",
        "pencere = 8 # context window (T)\n",
        "\n",
        "\n",
        "def get_batch(split, kume = 4):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = egitim if split == 'egitim' else test\n",
        "    ix = torch.randint(len(data) - pencere, (kume,))\n",
        "    x = torch.stack([data[i:i+pencere] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+pencere+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "xb, yb = get_batch('egitim')\n",
        "print('girdi:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('cikti:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(kume):\n",
        "    for t in range(pencere):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"girdi {context.tolist()} cikti: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksLZ7j131B7u",
        "outputId": "17aef9d2-a5d8-4507-e2fb-731a8419c925"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "girdi:\n",
            "torch.Size([4, 8])\n",
            "tensor([[80, 76, 79, 84, 76, 73, 66,  1],\n",
            "        [90, 65, 77, 65, 78,  1, 71, 69],\n",
            "        [68, 65, 13,  1, 75, 65, 82, 73],\n",
            "        [32,  1, 65, 77, 69, 82, 73, 75]])\n",
            "cikti:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 76,  79,  84,  76,  73,  66,   1,  75],\n",
            "        [ 65,  77,  65,  78,   1,  71,  69, 105],\n",
            "        [ 65,  13,   1,  75,  65,  82,  73,  89],\n",
            "        [  1,  65,  77,  69,  82,  73,  75,  65]])\n",
            "----\n",
            "girdi [80] cikti: 76\n",
            "girdi [80, 76] cikti: 79\n",
            "girdi [80, 76, 79] cikti: 84\n",
            "girdi [80, 76, 79, 84] cikti: 76\n",
            "girdi [80, 76, 79, 84, 76] cikti: 73\n",
            "girdi [80, 76, 79, 84, 76, 73] cikti: 66\n",
            "girdi [80, 76, 79, 84, 76, 73, 66] cikti: 1\n",
            "girdi [80, 76, 79, 84, 76, 73, 66, 1] cikti: 75\n",
            "girdi [90] cikti: 65\n",
            "girdi [90, 65] cikti: 77\n",
            "girdi [90, 65, 77] cikti: 65\n",
            "girdi [90, 65, 77, 65] cikti: 78\n",
            "girdi [90, 65, 77, 65, 78] cikti: 1\n",
            "girdi [90, 65, 77, 65, 78, 1] cikti: 71\n",
            "girdi [90, 65, 77, 65, 78, 1, 71] cikti: 69\n",
            "girdi [90, 65, 77, 65, 78, 1, 71, 69] cikti: 105\n",
            "girdi [68] cikti: 65\n",
            "girdi [68, 65] cikti: 13\n",
            "girdi [68, 65, 13] cikti: 1\n",
            "girdi [68, 65, 13, 1] cikti: 75\n",
            "girdi [68, 65, 13, 1, 75] cikti: 65\n",
            "girdi [68, 65, 13, 1, 75, 65] cikti: 82\n",
            "girdi [68, 65, 13, 1, 75, 65, 82] cikti: 73\n",
            "girdi [68, 65, 13, 1, 75, 65, 82, 73] cikti: 89\n",
            "girdi [32] cikti: 1\n",
            "girdi [32, 1] cikti: 65\n",
            "girdi [32, 1, 65] cikti: 77\n",
            "girdi [32, 1, 65, 77] cikti: 69\n",
            "girdi [32, 1, 65, 77, 69] cikti: 82\n",
            "girdi [32, 1, 65, 77, 69, 82] cikti: 73\n",
            "girdi [32, 1, 65, 77, 69, 82, 73] cikti: 75\n",
            "girdi [32, 1, 65, 77, 69, 82, 73, 75] cikti: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1500)\n",
        "\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # basit bir tablo (icerisinde olasiliklar var)\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, hedef=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if hedef is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            hedef = hedef.view(B*T)\n",
        "\n",
        "            loss = F.cross_entropy(logits, hedef)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def tahmin(self, idx, max_karakter):\n",
        "\n",
        "        for _ in range(max_karakter):\n",
        "\n",
        "            logits, loss = self(idx)\n",
        "\n",
        "            # sonuncu zamana odaklan\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # olasiliklari her bir kume icin normalize ediyoruz\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # yeni bir karakter seciyoruz\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # sona ekle\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(sozluk_buyuklugu)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbqiro2T3lEB",
        "outputId": "c6406cde-217a-45bb-f4fe-bb1c3215ac11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 135])\n",
            "tensor(5.7664, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ornekleme\n",
        "torch.multinomial(torch.tensor([0.1,0.1, 0.1, 0.1, 0.8]), num_samples=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DEdPApkSQp1",
        "outputId": "223daeff-5e37-4e2d-9b98-19a7e2283793"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.tahmin(idx = torch.zeros((1, 1), dtype=torch.long), max_karakter=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWStkl3uUkIH",
        "outputId": "ab86653d-ea1b-453f-ceab-36eb366d201c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "@z.qcs3éê’Ml m[ +Zé2]ücEYrîóYê£e“,°$J|^ı'šFa–Çsc=#èufêâ'¯bZTxA/d×ûBcEMjó•OñTLşRq=U,THÇ[AWRG¯zLë…ó#tV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer objesi olusturduk\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "H1C7cXa5XIq7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kume = 32\n",
        "for adim in range(10000):\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('egitim', kume=kume)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TscRvcrtXQNF",
        "outputId": "fda80725-699b-4384-e780-5d28bb663168"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6282131671905518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.ones((1, 1), dtype=torch.long)\n",
        "\n",
        "print(decode(m.tahmin(idx, max_karakter=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIzFRrHFY8Mk",
        "outputId": "c33d3369-d054-4334-9f05-0eca83bfc432"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1\n",
            "an gömadaakomerın selakendeó“aleğerın böntle be jLbiçlın 1, ha dasey epiyi padomeclekürajahtenek b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "8000000000//(135*135)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rQo5KLZbWoW",
        "outputId": "e12a3bf8-588d-4c19-fde6-5ad5e68b101c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "438957"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/eonurk/eksiGPT"
      ],
      "metadata": {
        "id": "g05YQG_5aeF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Burada ilk videoyu bitirdik! Peki neler ogrendik?\n",
        "\n",
        "* Dokümanların içerisindeki karakter sayısı boyutunu belirliyor. Bizim dokümanda 3.5 milyon karakter var yani yaklaşık 3.5 Megabyte.\n",
        "\n",
        "* Next token prediction, yani sonraki hece tahmini en önemli fikirlerden biri. Çünkü neyi tahmin etmemiz gerektiğini artık biliyoruz.\n",
        "\n",
        "* Normalde heceleri de tahmin edebiliriz ama biz şu anda karakterleri tahmin ediyoruz ve bunları teker teker yapıyoruz. Yani bir önceki harf diğerini takip ediyor. Buna literatürde bigram model deniliyor.\n",
        "Matematiksel olarak da şöyle:$$P(c_i​∣c_1​,c_2​,…,c_{i−1​})≈P(c_i​∣c_{i−1}​)$$ yani, bir dökümandaki i sıradaki karakteri tahmin etmek için normalde ondan önceki tüm karakterleri bilmemiz gerekir ama burada sadece i-1 inci karakteri (yani tahmin edilenden sadece bir önceki) bilmenin tüm karakterleri bilmeye eşit olduğunu varsayıyoruz. Tabi bu bi noktaya kadar doğru ve çok da iyi bir model değil! Örneğin 'anen göteğ' tahmin etmesi gibi :D"
      ],
      "metadata": {
        "id": "pan9u2XCboPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: **DIKKAT!** (**ATTENTION!**)"
      ],
      "metadata": {
        "id": "BZC-aSi_jbXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://arxiv.org/pdf/1706.03762 (Transformer makalesi)\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "B,T,C = 4,8,2 # kume, pencere, kanal (simdilik 2, normalde 135)\n",
        "x = torch.randn(B,T,C).float()\n",
        "x.shape"
      ],
      "metadata": {
        "id": "QBozYZKOjaYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e1fa3f-f0bf-41f8-ec64-2fc1abd4a7df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ornek endeksleme (indexing)\n",
        "\n",
        "print(x[0]) # (, T, C) = (T,C) = (8,2)\n",
        "# print(\"\\n\")\n",
        "# print(x[0, 0]) # (, , C) = (C) = (2)\n",
        "# print(\"\\n\")\n",
        "# print(x[:, 1, 1]) # (B, , ) = (B) = (4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHF72Bu70bXK",
        "outputId": "a85a065e-2d0f-4cbe-ef02-ab02a6dd8b1f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.3596, -0.9152],\n",
            "        [ 0.6258,  0.0255],\n",
            "        [ 0.9545,  0.0643],\n",
            "        [ 0.3612,  1.1679],\n",
            "        [-1.3499, -0.5102],\n",
            "        [ 0.2360, -0.2398],\n",
            "        [-0.9211,  1.5433]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ortalama = torch.zeros((B,T,C))\n",
        "\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "\n",
        "        onceki_x = x[b, :t+1] # (, t, C) = (t, C)\n",
        "\n",
        "        # zaman boyutunda o zamana kadarki ortalamalari (C)\n",
        "        x_ortalama[b,t] = torch.mean(onceki_x, dim=0)"
      ],
      "metadata": {
        "id": "M0qiKD-azwLL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1kL1VPI3nCv",
        "outputId": "1187aad0-f5c0-4e23-f493-8debf37e4a17"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ortalama[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLMivjVy4rVP",
        "outputId": "5aa49361-e0bd-42b4-a8df-67a0f8fbbdd1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hadi sağlama yapalım! :D\n",
        "print((0.1808 - 0.3596) /2)\n",
        "print((0.1808 - 0.3596 + 0.6258) /3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH4W6Kte4_Yk",
        "outputId": "1d8d2a46-f3fc-4365-9eb9-238c8b78c2f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0894\n",
            "0.14900000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIS MATEMATIGINE HOSGELDINIZ!\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "\n",
        "b = torch.randint(0,10,(3,3)).float()\n",
        "c = a @ b # kartezyen carpma islemi\n",
        "\n",
        "print(\"a:\\n\", a)\n",
        "print(\"\\n=======================\\n\")\n",
        "print(\"b:\\n\", b)\n",
        "print(\"\\n=======================\\n\")\n",
        "print(\"c:\\n\", c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1EtU4oy5jp4",
        "outputId": "b39267c2-4208-4c12-bf71-dbe1c15e1a6d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            " tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "\n",
            "=======================\n",
            "\n",
            "b:\n",
            " tensor([[5., 7., 2.],\n",
            "        [0., 5., 3.],\n",
            "        [5., 0., 4.]])\n",
            "\n",
            "=======================\n",
            "\n",
            "c:\n",
            " tensor([[5.0000, 7.0000, 2.0000],\n",
            "        [2.5000, 6.0000, 2.5000],\n",
            "        [3.3333, 4.0000, 3.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hadi saglama yapalim x2! :D\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "wei\n",
        "\n",
        "x_ortalama_2 = wei @ x # (, T, T) @ (B, T, C) = (B, T, C)\n",
        "\n",
        "print(x_ortalama[3])\n",
        "print(\"\\n=======================\\n\")\n",
        "print(x_ortalama_2[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4hCcE_g83wW",
        "outputId": "1d2e4406-a119-4b26-c77c-43f3b11e7106"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6455, -0.8030],\n",
            "        [ 1.4985, -0.5395],\n",
            "        [ 0.4954,  0.3420],\n",
            "        [ 1.0623, -0.1802],\n",
            "        [ 1.1401, -0.4462],\n",
            "        [ 1.0870, -0.4071],\n",
            "        [ 1.0430, -0.1299],\n",
            "        [ 1.1138, -0.1641]])\n",
            "\n",
            "=======================\n",
            "\n",
            "tensor([[ 1.6455, -0.8030],\n",
            "        [ 1.4985, -0.5395],\n",
            "        [ 0.4954,  0.3420],\n",
            "        [ 1.0623, -0.1802],\n",
            "        [ 1.1401, -0.4462],\n",
            "        [ 1.0870, -0.4071],\n",
            "        [ 1.0430, -0.1299],\n",
            "        [ 1.1138, -0.1641]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aynisini bir daha yapiyoruz bu sefer softmax ile!\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "x_ortalama_3 = wei @ x\n",
        "\n",
        "print(x_ortalama_2[0])\n",
        "print(\"\\n=======================\\n\")\n",
        "print(x_ortalama_3[0])"
      ],
      "metadata": {
        "id": "D0gCnA-3Byh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a15fb6-3c89-4919-a369-c3ac67fd6917"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "\n",
            "=======================\n",
            "\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# CLIMAX!\n",
        "# Attention - Dikkat!\n",
        "# https://arxiv.org/pdf/1706.03762\n",
        "\n",
        "# tek basli dikkat\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "\n",
        "dikkat_buyuklugu = 4 # (H)\n",
        "\n",
        "# 2 tane giris 4 tane cikis\n",
        "anahtar = nn.Linear(C, dikkat_buyuklugu, bias = False) # (C, H)\n",
        "sorgu   = nn.Linear(C, dikkat_buyuklugu, bias = False) # (C, H)\n",
        "\n",
        "# > | >\n",
        "#   | >\n",
        "# > | >\n",
        "#   | >\n",
        "\n",
        "k = anahtar(x) # key (B,T,H)\n",
        "q = sorgu(x) # query (B,T,H)\n",
        "\n",
        "wei = k @ q.transpose(-2, -1) * dikkat_buyuklugu ** -0.5 # (B, T, H) @ (B, H, T) -> (B, T, T)\n",
        "\n",
        "print(wei.var())\n",
        "# wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "print(wei[0]) # (T,T)\n",
        "\n",
        "cikti = wei @ x # (B, T, T) @ (B, T, C) = (B, T, C)"
      ],
      "metadata": {
        "id": "Rj7T7vnjG8wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a0eba3-8cf7-4624-83b6-543d5b97e207"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2593, grad_fn=<VarBackward0>)\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4853, 0.5147, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3345, 0.2980, 0.3675, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2333, 0.1957, 0.2701, 0.3009, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1878, 0.1774, 0.2230, 0.2549, 0.1568, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1421, 0.1816, 0.1107, 0.0918, 0.1413, 0.3325, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1366, 0.1444, 0.1452, 0.1516, 0.1373, 0.1419, 0.0000],\n",
            "        [0.1324, 0.1590, 0.1354, 0.1389, 0.0945, 0.1265, 0.1399, 0.0734]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,dikkat_buyuklugu)\n",
        "q = torch.randn(B,T,dikkat_buyuklugu)\n",
        "\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "\n",
        "print(wei.var())\n",
        "\n",
        "wei = wei * dikkat_buyuklugu ** -0.5\n",
        "\n",
        "print(\"\\n\", wei.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkrvP6eJMyxC",
        "outputId": "41b81541-dead-4dd6-e0cd-636713b51010"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.5029)\n",
            "\n",
            " tensor(1.1257)\n"
          ]
        }
      ]
    }
  ]
}